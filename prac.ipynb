{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf85f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,List,Dict,Optional,Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetryState(TypedDict):\n",
    "    rag:int\n",
    "    web_search:int\n",
    "    synthesis:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalResult(TypedDict):\n",
    "    source: Literal[\"rag\", \"web\"]\n",
    "    title: str\n",
    "    content: str\n",
    "    url: Optional[str]\n",
    "    score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1db98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,List,Dict,Optional,Literal\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_query:str\n",
    "\n",
    "    confidence_score:float\n",
    "    retrieval_mode:Literal['rag','web','both','none']\n",
    "    research_relevant:bool\n",
    "    answer_mode:Literal['grounded','direct','refuse']\n",
    "\n",
    "    rag_results:Optional[List[RetrievalResult]]\n",
    "    web_search_results:Optional[List[RetrievalResult]]\n",
    "    merged_results:Optional[List[RetrievalResult]]\n",
    "\n",
    "    retries:RetryState\n",
    "    max_retries:RetryState\n",
    "\n",
    "    failure_response:Optional[str]\n",
    "    response:Optional[str]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"planner\", planner_node)\n",
    "graph.add_node(\"rag\", rag_node)\n",
    "graph.add_node(\"web_search\", websearch_node)\n",
    "graph.add_node(\"confidence_checker\", confidence_checker)\n",
    "graph.add_node(\"evaluator\", evaluator_node)\n",
    "graph.add_node(\"summarizer\", summarizer_node)\n",
    "graph.add_node(\"failure_node\", failure_node)\n",
    "\n",
    "graph.set_entry_point(\"planner\")\n",
    "\n",
    "# Planner decides retrieval\n",
    "graph.add_conditional_edges(\n",
    "    \"planner\",\n",
    "    planner_router,\n",
    "    {\n",
    "        \"rag\": \"rag\",\n",
    "        \"web\": \"web_search\",\n",
    "        \"both\": [\"rag\", \"web_search\"],\n",
    "        \"none\": \"failure_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Retrieval → confidence\n",
    "graph.add_edge(\"rag\", \"confidence_checker\")\n",
    "graph.add_edge(\"web_search\", \"confidence_checker\")\n",
    "\n",
    "# Confidence → evaluation\n",
    "graph.add_edge(\"confidence_checker\", \"evaluator\")\n",
    "\n",
    "# Evaluation controls loop\n",
    "graph.add_conditional_edges(\n",
    "    \"evaluator\",\n",
    "    evaluation_router,\n",
    "    {\n",
    "        \"planner\": \"planner\",\n",
    "        \"failed\": \"failure_node\",\n",
    "        \"enough\": \"summarizer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"summarizer\", END)\n",
    "graph.add_edge(\"failure_node\", END)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc0fd8a",
   "metadata": {},
   "source": [
    "<h1>Planner Node</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff428de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_classic.prompts import ChatPromptTemplate\n",
    "\n",
    "class PlannerOutput(BaseModel):\n",
    "    research_relevant: bool\n",
    "    retrieval_mode: Literal[\"rag\", \"web\", \"both\", \"none\"]\n",
    "    answer_mode: Literal[\"grounded\",\"direct\",\"refuse\"]\n",
    "    confidence: float = Field(ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=PlannerOutput)\n",
    "\n",
    "\n",
    "PLANNER_PROMPT = \"\"\"You are a planning module inside an AI research assistant.\n",
    "\n",
    "You DO NOT answer the user.\n",
    "You DO NOT explain your reasoning.\n",
    "You ONLY decide how the system should respond.\n",
    "\n",
    "You have access to:\n",
    "- A large internal vector store containing AI / ML / NLP / LLM / Systems research papers, surveys, benchmarks, and technical articles.\n",
    "- A web search tool for retrieving recent, external, or missing research information.\n",
    "\n",
    "Your job is to analyze the user query and output a structured decision describing:\n",
    "1. Whether the query is research-related\n",
    "2. How information should be retrieved (if at all)\n",
    "3. How the answer should be produced\n",
    "4. How confident you are in these decisions\n",
    "\n",
    "--------------------------------\n",
    "1. RESEARCH RELEVANCE\n",
    "--------------------------------\n",
    "A query IS research-related if it involves:\n",
    "- Research papers, surveys, or academic work\n",
    "- Models, algorithms, architectures, or methods\n",
    "- Benchmarks, evaluations, comparisons, or ablations\n",
    "- Technical analysis of AI/ML/NLP/LLMs/Systems\n",
    "\n",
    "A query is NOT research-related if it involves:\n",
    "- Casual conversation or chit-chat\n",
    "- Opinions, jokes, or storytelling\n",
    "- Personal advice or life questions\n",
    "- Shopping, travel, or entertainment\n",
    "- General trivia without technical depth\n",
    "\n",
    "Set:\n",
    "- research_relevant = true or false\n",
    "\n",
    "--------------------------------\n",
    "2. RETRIEVAL MODE\n",
    "--------------------------------\n",
    "If research_relevant = false:\n",
    "- retrieval_mode MUST be \"none\"\n",
    "\n",
    "If research_relevant = true, choose exactly ONE:\n",
    "\n",
    "Use \"rag\" if:\n",
    "- The topic is established or well-documented\n",
    "- Surveys, classic papers, or known methods are sufficient\n",
    "- Internal vector store is likely enough\n",
    "\n",
    "Use \"web\" if:\n",
    "- The query explicitly asks for recent, latest, or current work\n",
    "- The topic involves fast-moving developments\n",
    "- External or up-to-date sources are required\n",
    "\n",
    "Use \"both\" if:\n",
    "- Foundational research exists internally\n",
    "- AND recent updates, comparisons, or new papers may be required\n",
    "\n",
    "Rules:\n",
    "- Do NOT assume freshness unless explicitly requested\n",
    "- Prefer internal knowledge when possible\n",
    "- Be conservative: choose \"both\" only when clearly necessary\n",
    "- Never hallucinate missing information\n",
    "\n",
    "--------------------------------\n",
    "3. ANSWER MODE\n",
    "--------------------------------\n",
    "Decide how the answer should be produced:\n",
    "\n",
    "Use \"direct\" ONLY if:\n",
    "- The question is simple, factual, and well-established\n",
    "- The answer is unlikely to change over time\n",
    "- No citations, verification, or freshness are required\n",
    "\n",
    "Use \"grounded\" if:\n",
    "- The query is research-related\n",
    "- Evidence, papers, or verification are expected\n",
    "- Even if you know the answer, it should be supported by sources\n",
    "\n",
    "Use \"refuse\" if:\n",
    "- The query is not research-related\n",
    "- Or answering would require speculation or unsupported claims\n",
    "\n",
    "Rules:\n",
    "- For research questions, default to \"grounded\" unless clearly trivial\n",
    "- Do NOT choose \"direct\" just because you know the answer\n",
    "- Research assistants prefer evidence over memory\n",
    "\n",
    "--------------------------------\n",
    "4. CONSISTENCY RULES (STRICT)\n",
    "--------------------------------\n",
    "These rules MUST ALWAYS hold:\n",
    "\n",
    "- If research_relevant = false:\n",
    "  - retrieval_mode MUST be \"none\"\n",
    "  - answer_mode MUST be \"refuse\"\n",
    "\n",
    "- If answer_mode = \"direct\":\n",
    "  - retrieval_mode MUST be \"none\"\n",
    "\n",
    "- If answer_mode = \"grounded\":\n",
    "  - retrieval_mode MUST NOT be \"none\"\n",
    "\n",
    "--------------------------------\n",
    "5. CONFIDENCE\n",
    "--------------------------------\n",
    "Provide a confidence score between 0.0 and 1.0 indicating how certain you are that:\n",
    "- research_relevant\n",
    "- retrieval_mode\n",
    "- answer_mode\n",
    "\n",
    "are all correct.\n",
    "\n",
    "Confidence interpretation:\n",
    "- ≥ 0.8 → clear and unambiguous decision\n",
    "- 0.5–0.8 → some uncertainty, retries may be useful\n",
    "- < 0.5 → high uncertainty\n",
    "\n",
    "--------------------------------\n",
    "OUTPUT FORMAT (STRICT)\n",
    "--------------------------------\n",
    "Output ONLY valid JSON that conforms exactly to the provided schema.\n",
    "Do NOT include explanations, comments, or extra text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt=ChatPromptTemplate([\n",
    "    (\"system\",PLANNER_PROMPT+\"\\n\\n{format_instructions}\"),\n",
    "    (\"user\",'{user_query}')\n",
    "]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | llm |parser\n",
    "\n",
    "response=chain.invoke({\"user_query\":\"who are ypou\"})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b595edb",
   "metadata": {},
   "source": [
    "<h1>RAG INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6edf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = {\n",
    "    \"computer_vision\": \"computer vision\",\n",
    "    \"nlp\": \"natural language processing\",\n",
    "    \"deep_learning\": \"deep learning\",\n",
    "    \"transformers\": \"transformer models\",\n",
    "    \"diffusion\": \"diffusion models\",\n",
    "    \"reinforcement_learning\": \"reinforcement learning\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e95408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest.py\n",
    "import os\n",
    "import json\n",
    "import arxiv\n",
    "import fitz\n",
    "import time\n",
    "import uuid\n",
    "import urllib.error\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "TARGET_PAPER_COUNT = 100\n",
    "RESULTS_PER_TOPIC = 40   # oversample because some will fail\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "PDF_DIR = os.path.join(DATA_DIR, \"pdfs\")\n",
    "META_DIR = os.path.join(DATA_DIR, \"metadata\")\n",
    "\n",
    "COLLECTION_NAME = \"arxiv_ai_research_papers\"\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "TOPICS = {\n",
    "    \"computer_vision\": \"computer vision\",\n",
    "    \"nlp\": \"natural language processing\",\n",
    "    \"deep_learning\": \"deep learning\",\n",
    "    \"transformers\": \"transformer models\",\n",
    "    \"diffusion\": \"diffusion models\",\n",
    "    \"reinforcement_learning\": \"reinforcement learning\"\n",
    "}\n",
    "\n",
    "# ---------------- SETUP ----------------\n",
    "os.makedirs(PDF_DIR, exist_ok=True)\n",
    "os.makedirs(META_DIR, exist_ok=True)\n",
    "\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "qdrant = QdrantClient(path='./qdrant_data')\n",
    "\n",
    "if COLLECTION_NAME not in [c.name for c in qdrant.get_collections().collections]:\n",
    "    qdrant.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(\n",
    "            size=embedder.get_sentence_embedding_dimension(),\n",
    "            distance=Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def extract_text(pdf_path: str) -> str:\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        return \"\\n\".join(page.get_text() for page in doc)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def safe_download(paper, pdf_path, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            paper.download_pdf(filename=pdf_path)\n",
    "            return True\n",
    "        except (urllib.error.HTTPError, urllib.error.URLError) as e:\n",
    "            time.sleep(2)\n",
    "        except Exception:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "# ---------------- INGEST ----------------\n",
    "points = []\n",
    "bm25_corpus = []\n",
    "bm25_ids = []\n",
    "seen_ids = set()\n",
    "\n",
    "successful_papers = 0\n",
    "\n",
    "for topic, query in TOPICS.items():\n",
    "    if successful_papers >= TARGET_PAPER_COUNT:\n",
    "        break\n",
    "\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=RESULTS_PER_TOPIC,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    for paper in tqdm(search.results(), desc=f\"Ingesting {topic}\"):\n",
    "        if successful_papers >= TARGET_PAPER_COUNT:\n",
    "            break\n",
    "\n",
    "        arxiv_id = paper.get_short_id()\n",
    "        if arxiv_id in seen_ids:\n",
    "            continue\n",
    "\n",
    "        seen_ids.add(arxiv_id)\n",
    "\n",
    "        pdf_path = os.path.join(PDF_DIR, f\"{arxiv_id}.pdf\")\n",
    "        meta_path = os.path.join(META_DIR, f\"{arxiv_id}.json\")\n",
    "\n",
    "        # ---- SAFE PDF DOWNLOAD\n",
    "        downloaded = safe_download(paper, pdf_path)\n",
    "        if not downloaded:\n",
    "            continue\n",
    "\n",
    "        # ---- METADATA\n",
    "        metadata = {\n",
    "            \"arxiv_id\": arxiv_id,\n",
    "            \"title\": paper.title,\n",
    "            \"authors\": [a.name for a in paper.authors],\n",
    "            \"summary\": paper.summary,\n",
    "            \"published\": paper.published.isoformat(),\n",
    "            \"updated\": paper.updated.isoformat(),\n",
    "            \"categories\": paper.categories,\n",
    "            \"topic\": topic,\n",
    "            \"pdf_path\": pdf_path,\n",
    "            \"arxiv_url\": paper.entry_id\n",
    "        }\n",
    "\n",
    "        with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "        # ---- TEXT EXTRACTION\n",
    "        text = extract_text(pdf_path)\n",
    "        if len(text.strip()) < 500:\n",
    "            continue  # trash PDFs\n",
    "\n",
    "        # ---- EMBEDDING\n",
    "        embedding = embedder.encode(text, normalize_embeddings=True)\n",
    "\n",
    "        tokens = text.lower().split()\n",
    "        bm25_corpus.append(tokens)\n",
    "        bm25_ids.append(arxiv_id)\n",
    "\n",
    "        point_id = uuid.uuid5(\n",
    "            uuid.NAMESPACE_URL,\n",
    "            f\"https://arxiv.org/abs/{arxiv_id}\"\n",
    "        )\n",
    "\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=str(point_id),  # ✅ valid UUID\n",
    "                vector=embedding.tolist(),\n",
    "                payload=metadata  # contains arxiv_id safely\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        successful_papers += 1\n",
    "\n",
    "# ---------------- STORE ----------------\n",
    "qdrant.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"bm25.json\"), \"w\") as f:\n",
    "    json.dump({\"ids\": bm25_ids, \"corpus\": bm25_corpus}, f)\n",
    "\n",
    "print(f\"SUCCESS: Downloaded and indexed {successful_papers} papers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b620177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# ---- Load BM25 data\n",
    "with open(\"data/bm25.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "corpus = data[\"corpus\"]\n",
    "ids = data[\"ids\"]\n",
    "\n",
    "bm25 = BM25Okapi(corpus)\n",
    "\n",
    "# ---- Query\n",
    "query = \"diffusion model image generation\"\n",
    "query_tokens = query.lower().split()\n",
    "\n",
    "scores = bm25.get_scores(query_tokens)\n",
    "top_k = sorted(\n",
    "    zip(ids, scores),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:5]\n",
    "\n",
    "print(\"BM25 RESULTS:\")\n",
    "for arxiv_id, score in top_k:\n",
    "    print(arxiv_id, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f41484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "COLLECTION = \"arxiv_ai_research_papers\"\n",
    "\n",
    "client = QdrantClient(path='./qdrant_data')\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"transformer architectures for large language models\"\n",
    "query_vector = embedder.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "response = client.query_points(\n",
    "    collection_name=COLLECTION,\n",
    "    query=query_vector,\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(\"QDRANT RESULTS:\")\n",
    "for p in response.points:\n",
    "    print(p.payload[\"arxiv_id\"], p.payload[\"title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45925bed",
   "metadata": {},
   "source": [
    "<h1> RAG RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "COLLECTION = \"arxiv_ai_research_papers\"\n",
    "\n",
    "# ---- Load BM25\n",
    "with open(\"data/bm25.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "bm25 = BM25Okapi(data[\"corpus\"])\n",
    "ids = data[\"ids\"]\n",
    "\n",
    "# ---- Init\n",
    "client = QdrantClient(path='./qdrant_data')\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"diffusion models for computer vision\"\n",
    "tokens = query.lower().split()\n",
    "\n",
    "# ---- BM25 stage\n",
    "bm25_scores = bm25.get_scores(tokens)\n",
    "bm25_top = sorted(\n",
    "    zip(ids, bm25_scores),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:30]\n",
    "\n",
    "bm25_ids = set(i for i, _ in bm25_top)\n",
    "\n",
    "# ---- Dense stage\n",
    "query_vector = embedder.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "dense = client.query_points(\n",
    "    collection_name=COLLECTION,\n",
    "    query=query_vector,\n",
    "    limit=20,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(\"HYBRID RESULTS:\")\n",
    "for p in dense.points:\n",
    "    if p.payload[\"arxiv_id\"] in bm25_ids:\n",
    "        print(p.payload[\"arxiv_id\"], p.payload[\"title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a82e4",
   "metadata": {},
   "source": [
    "<h1> Websearch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ca11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "client = TavilyClient(os.environ.get(\"TAVILY_API_KEY\"))\n",
    "response = client.search(\n",
    "    query=\"What are the latest developments in quantum computing?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class RagRetrievalResult(BaseModel):\n",
    "    source: Literal[\"rag\"] = \"rag\"\n",
    "\n",
    "    arxiv_id: str\n",
    "    title: str\n",
    "    abstract: Optional[str]\n",
    "\n",
    "    bm25_score: float\n",
    "    dense_score: float\n",
    "    relevance_score: float\n",
    "\n",
    "    url: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def rag_retrieve(query: str) -> List[RagRetrievalResult]:\n",
    "    tokens = query.lower().split()\n",
    "\n",
    "    # ---- BM25 stage\n",
    "    bm25_scores = bm25.get_scores(tokens)\n",
    "    bm25_top = sorted(\n",
    "        zip(ids, bm25_scores),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:30]\n",
    "\n",
    "    bm25_map = {i: score for i, score in bm25_top}\n",
    "\n",
    "    # ---- Dense stage\n",
    "    query_vector = embedder.encode(\n",
    "        query,\n",
    "        normalize_embeddings=True\n",
    "    ).tolist()\n",
    "\n",
    "    dense = client.query_points(\n",
    "        collection_name=COLLECTION,\n",
    "        query=query_vector,\n",
    "        limit=20,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "\n",
    "    results: List[RagRetrievalResult] = []\n",
    "\n",
    "    for p in dense.points:\n",
    "        arxiv_id = p.payload.get(\"arxiv_id\")\n",
    "\n",
    "        # enforce hybrid intersection\n",
    "        if arxiv_id not in bm25_map:\n",
    "            continue\n",
    "\n",
    "        bm25_score = bm25_map[arxiv_id]\n",
    "        dense_score = p.score\n",
    "\n",
    "        # simple but effective fusion\n",
    "        relevance_score = 0.6 * dense_score + 0.4 * min(bm25_score / 10.0, 1.0)\n",
    "\n",
    "        results.append(\n",
    "            RagRetrievalResult(\n",
    "                arxiv_id=arxiv_id,\n",
    "                title=p.payload.get(\"title\", \"\"),\n",
    "                abstract=p.payload.get(\"abstract\"),\n",
    "                bm25_score=bm25_score,\n",
    "                dense_score=dense_score,\n",
    "                relevance_score=relevance_score,\n",
    "                url=f\"https://arxiv.org/abs/{arxiv_id}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # sort by final relevance\n",
    "    results.sort(key=lambda r: r.relevance_score, reverse=True)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class WebRetrievalResult(BaseModel):\n",
    "    source: Literal[\"web\"] = \"web\"\n",
    "\n",
    "    title: str\n",
    "    content: str\n",
    "    url: str\n",
    "\n",
    "    relevance_score: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from tavily import TavilyClient\n",
    "\n",
    "tavily = TavilyClient(os.environ.get(\"TAVILY_API_KEY\"))\n",
    "\n",
    "def web_search(query: str, k: int = 8) -> List[WebRetrievalResult]:\n",
    "    response = tavily.search(\n",
    "        query=query,\n",
    "        max_results=k\n",
    "    )\n",
    "\n",
    "    results: List[WebRetrievalResult] = []\n",
    "\n",
    "    for r in response.get(\"results\", []):\n",
    "        results.append(\n",
    "            WebRetrievalResult(\n",
    "                title=r.get(\"title\", \"\"),\n",
    "                content=r.get(\"content\", \"\"),\n",
    "                url=r.get(\"url\"),\n",
    "                relevance_score=float(r.get(\"score\", 0.5))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0e040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinn\\anaconda3\\envs\\gemini\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.graph.graph import graph\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "initial_state = {\n",
    "    \"user_query\": \"What is gradient descent?\",\n",
    "    \"rag_results\": [],\n",
    "    \"web_search_results\": [],\n",
    "    \"evidence_score\": None,\n",
    "    \"retries\": {\n",
    "        \"rag\": 0,\n",
    "        \"web\": 0,\n",
    "        \"synthesis\": 0\n",
    "    },\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(result[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122627d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01matexit\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqdrant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m close_qdrant_client\n\u001b[1;32m----> 3\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m      5\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_query\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me about the recent updates in the architercture of transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag_results\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m     25\u001b[0m     initial_state,\n\u001b[0;32m     26\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m ):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import atexit\n",
    "from app.llm.qdrant import close_qdrant_client\n",
    "app = graph.compile()\n",
    "\n",
    "initial_state = {\n",
    "    \"user_query\": \"Tell me about the recent updates in the architercture of transformers\",\n",
    "    \"rag_results\": [],\n",
    "    \"web_search_results\": [],\n",
    "    \"evidence_score\": None,\n",
    "    \"retries\": {\n",
    "        \"rag\": 0,\n",
    "        \"web_search\": 0,\n",
    "        \"synthesis\": 0\n",
    "    },\n",
    "    \"max_retries\": {\n",
    "        \"rag\": 2,\n",
    "        \"web_search\": 2,\n",
    "        \"synthesis\": 2\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for event in app.stream(\n",
    "    initial_state,\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    print(event)\n",
    "\n",
    "atexit.register(close_qdrant_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a12890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinn\\anaconda3\\envs\\gemini\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.graph.graph import graph\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72314f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'research_relevant': True, 'retrieval_mode': 'both', 'answer_mode': 'grounded', 'effective_query': 'Just tell me something about Artificial Intelligence search for vector db and web search for better results'}}\n",
      "{'both_retrieval': {'user_query': 'Just tell me something about Artificial Intelligence search for vector db and web search for better results', 'effective_query': 'Just tell me something about Artificial Intelligence search for vector db and web search for better results', 'retrieval_mode': 'both', 'answer_mode': 'grounded', 'research_relevant': True, 'rag_results': [], 'web_search_results': [], 'evidence_score': None, 'retries': {'rag': 0, 'web_search': 0, 'synthesis': 0}, 'max_retries': {'rag': 2, 'web_search': 2, 'synthesis': 2}}}\n",
      "{'rag': {'rag_results': [RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2101.11436v1', title='Challenges Encountered in Turkish Natural Language Processing Studies', url='https://arxiv.org/abs/2101.11436v1', abstract=None, text=None, year=2021, version='v1', bm25_score=19.967015672364255, dense_score=0.34348000758829506, relevance_score=0.6060880045529771), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='1911.01248v1', title='A Holistic Natural Language Generation Framework for the Semantic Web', url='https://arxiv.org/abs/1911.01248v1', abstract=None, text=None, year=2019, version='v1', bm25_score=23.65424496643145, dense_score=0.28302006652005507, relevance_score=0.569812039912033), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2110.08975v2', title='Deep Transfer Learning & Beyond: Transformer Language Models in Information Systems Research', url='https://arxiv.org/abs/2110.08975v2', abstract=None, text=None, year=2021, version='v2', bm25_score=27.27540580856683, dense_score=0.27974322927572637, relevance_score=0.5678459375654359), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2307.10652v5', title='Exploring the Landscape of Natural Language Processing Research', url='https://arxiv.org/abs/2307.10652v5', abstract=None, text=None, year=2023, version='v5', bm25_score=20.71085604982439, dense_score=0.2685203407287281, relevance_score=0.5611122044372369), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2105.04026v2', title='The Modern Mathematics of Deep Learning', url='https://arxiv.org/abs/2105.04026v2', abstract=None, text=None, year=2021, version='v2', bm25_score=20.41165713994757, dense_score=0.2572103106264312, relevance_score=0.5543261863758587), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2005.03812v1', title='Comparative Analysis of Word Embeddings for Capturing Word Similarities', url='https://arxiv.org/abs/2005.03812v1', abstract=None, text=None, year=2020, version='v1', bm25_score=19.533843225982807, dense_score=0.25477088805699605, relevance_score=0.5528625328341976), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2107.03844v3', title='A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models', url='https://arxiv.org/abs/2107.03844v3', abstract=None, text=None, year=2021, version='v3', bm25_score=23.083906433428233, dense_score=0.25474763706034526, relevance_score=0.5528485822362071), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2306.06371v1', title='A Comprehensive Review of State-of-The-Art Methods for Java Code Generation from Natural Language Text', url='https://arxiv.org/abs/2306.06371v1', abstract=None, text=None, year=2023, version='v1', bm25_score=23.023405517490325, dense_score=0.24860914687034505, relevance_score=0.549165488122207), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='1807.09844v2', title='Modular Mechanistic Networks: On Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing', url='https://arxiv.org/abs/1807.09844v2', abstract=None, text=None, year=2018, version='v2', bm25_score=20.83739341767114, dense_score=0.2392721049020157, relevance_score=0.5435632629412095), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2310.14025v1', title='Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation', url='https://arxiv.org/abs/2310.14025v1', abstract=None, text=None, year=2023, version='v1', bm25_score=23.844177660551896, dense_score=0.239268442924103, relevance_score=0.5435610657544618)], 'rag_done': True, 'rag_failed': False}}\n",
      "{'web_search': {'web_search_results': [WebRetrievalResult(source_type='web', source_id='towardsai.net', title='14 Vector Database Optimization Tips for Faster AI Search', url='https://towardsai.net/p/machine-learning/14-vector-database-optimization-tips-for-faster-ai-search', content='* 14 Vector Database Optimization Tips for Faster AI Search. # 14 Vector Database Optimization Tips for Faster AI Search. Vector databases like **Pinecone, Weaviate, Milvus, and FAISS** are the backbone of modern AI applications — from RAG (Retrieval-Augmented Generation) to semantic search and recommendation systems. **Why it matters:** Common queries (e.g., top trending products) can be cached to **avoid repeated expensive vector searches**. By implementing these 14 techniques, engineers can significantly reduce query latency, save memory and operational costs, improve recall and relevance, and deliver reliable, real-time AI search experiences. Whether you are building RAG systems, recommendation engines, or semantic search applications, these optimizations ensure your AI performs at its best. ### Beyond Vector Search: Building an Adaptive Retrieval Router for Agentic AI Systems. ##### Beyond Vector Search: Building an Adaptive Retrieval Router for Agentic AI Systems.', snippet='* 14 Vector Database Optimization Tips for Faster AI Search. # 14 Vector Database Optimization Tips for Faster AI Search. Vector databases like **Pinecone, Weaviate, Milvus, and FAISS** are the backbone of modern AI applications — from RAG (Retrieval-Augmented Generation) to semantic search and recommendation systems. **Why it matters:** Common queries (e.g., top trending products) can be cached to **avoid repeated expensive vector searches**. By implementing these 14 techniques, engineers can s', published_at=None, retrieved_at='2026-01-03T05:35:52.201589', relevance_score=0.6745014), WebRetrievalResult(source_type='web', source_id='dev.to', title='Unlocking the Power of Vector Databases and AI Search', url='https://dev.to/sabaristacksurge/unlocking-the-power-of-vector-databases-and-ai-search-a-comprehensive-guide-12m4', content='Vector Databases: Ideal for similarity searches on high-dimensional data, with applications in recommendation systems, NLP, and computer vision.', snippet='Vector Databases: Ideal for similarity searches on high-dimensional data, with applications in recommendation systems, NLP, and computer vision.', published_at=None, retrieved_at='2026-01-03T05:35:52.202586', relevance_score=0.44927242), WebRetrievalResult(source_type='web', source_id='techwithram.medium.com', title='Vector Databases Unlocked: Your Key Next-Gen AI Search', url='https://techwithram.medium.com/the-ultimate-guide-to-vector-databases-f0bed41a1243', content='A vector database is a purpose-built system designed to store, index, and search through vector embeddings efficiently — especially at scale.', snippet='A vector database is a purpose-built system designed to store, index, and search through vector embeddings efficiently — especially at scale.', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.4179133), WebRetrievalResult(source_type='web', source_id='www.youtube.com', title='Vector Databases: The Secret Weapon for AI Search', url='https://www.youtube.com/watch?v=Ps913CUN1Tw', content=\"Discover how vector databases power fast, intelligent AI search and recommendations. Learn what vector databases are, why they're essential\", snippet=\"Discover how vector databases power fast, intelligent AI search and recommendations. Learn what vector databases are, why they're essential\", published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.3802761), WebRetrievalResult(source_type='web', source_id='www.searchenginejournal.com', title='Introduction To Vector Databases And How To Use AI For ...', url='https://www.searchenginejournal.com/introduction-to-vector-databases-and-how-to-use-ai-for-seo/533993/', content=\"1. Understanding Vector Databases · 2. Create A Vector Database · 3. Export Your Articles From Your CMS · 4. Inserting OpenAi's Text Embeddings\", snippet=\"1. Understanding Vector Databases · 2. Create A Vector Database · 3. Export Your Articles From Your CMS · 4. Inserting OpenAi's Text Embeddings\", published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.36963415), WebRetrievalResult(source_type='web', source_id='vegavid.com', title='How Do Vector Databases Work in AI Applications?', url='https://vegavid.com/blog/how-vector-databases-work-ai', content='Vector databases use specialized indexing techniques that reduce search space and improve performance. These indexes allow the database to', snippet='Vector databases use specialized indexing techniques that reduce search space and improve performance. These indexes allow the database to', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.35763538), WebRetrievalResult(source_type='web', source_id='hackread.com', title='The Power of Vector Databases in the New Era of AI Search', url='https://hackread.com/power-of-vector-databases-era-of-ai-search/', content='Step 1: Translating the World into Numbers with Embeddings · Step 2: The Speed of Search: Introducing the Vector Database · Step 3: Real-World', snippet='Step 1: Translating the World into Numbers with Embeddings · Step 2: The Speed of Search: Introducing the Vector Database · Step 3: Real-World', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.35608885), WebRetrievalResult(source_type='web', source_id='www.oracle.com', title='What Is Vector Search? The Ultimate Guide', url='https://www.oracle.com/database/vector-search/', content='Vector search enables efficient and scalable search in high-dimensional data, allowing for fast retrieval of similar items from large data sets.', snippet='Vector search enables efficient and scalable search in high-dimensional data, allowing for fast retrieval of similar items from large data sets.', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.26172626)], 'web_done': True, 'web_failed': False}}\n",
      "{'merge': {'rag_results': [RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2101.11436v1', title='Challenges Encountered in Turkish Natural Language Processing Studies', url='https://arxiv.org/abs/2101.11436v1', abstract=None, text=None, year=2021, version='v1', bm25_score=19.967015672364255, dense_score=0.34348000758829506, relevance_score=0.6060880045529771), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='1911.01248v1', title='A Holistic Natural Language Generation Framework for the Semantic Web', url='https://arxiv.org/abs/1911.01248v1', abstract=None, text=None, year=2019, version='v1', bm25_score=23.65424496643145, dense_score=0.28302006652005507, relevance_score=0.569812039912033), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2110.08975v2', title='Deep Transfer Learning & Beyond: Transformer Language Models in Information Systems Research', url='https://arxiv.org/abs/2110.08975v2', abstract=None, text=None, year=2021, version='v2', bm25_score=27.27540580856683, dense_score=0.27974322927572637, relevance_score=0.5678459375654359), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2307.10652v5', title='Exploring the Landscape of Natural Language Processing Research', url='https://arxiv.org/abs/2307.10652v5', abstract=None, text=None, year=2023, version='v5', bm25_score=20.71085604982439, dense_score=0.2685203407287281, relevance_score=0.5611122044372369), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2105.04026v2', title='The Modern Mathematics of Deep Learning', url='https://arxiv.org/abs/2105.04026v2', abstract=None, text=None, year=2021, version='v2', bm25_score=20.41165713994757, dense_score=0.2572103106264312, relevance_score=0.5543261863758587), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2005.03812v1', title='Comparative Analysis of Word Embeddings for Capturing Word Similarities', url='https://arxiv.org/abs/2005.03812v1', abstract=None, text=None, year=2020, version='v1', bm25_score=19.533843225982807, dense_score=0.25477088805699605, relevance_score=0.5528625328341976), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2107.03844v3', title='A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models', url='https://arxiv.org/abs/2107.03844v3', abstract=None, text=None, year=2021, version='v3', bm25_score=23.083906433428233, dense_score=0.25474763706034526, relevance_score=0.5528485822362071), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2306.06371v1', title='A Comprehensive Review of State-of-The-Art Methods for Java Code Generation from Natural Language Text', url='https://arxiv.org/abs/2306.06371v1', abstract=None, text=None, year=2023, version='v1', bm25_score=23.023405517490325, dense_score=0.24860914687034505, relevance_score=0.549165488122207), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='1807.09844v2', title='Modular Mechanistic Networks: On Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing', url='https://arxiv.org/abs/1807.09844v2', abstract=None, text=None, year=2018, version='v2', bm25_score=20.83739341767114, dense_score=0.2392721049020157, relevance_score=0.5435632629412095), RagRetrievalResult(source_type='rag', source_id='arxiv', arxiv_id='2310.14025v1', title='Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation', url='https://arxiv.org/abs/2310.14025v1', abstract=None, text=None, year=2023, version='v1', bm25_score=23.844177660551896, dense_score=0.239268442924103, relevance_score=0.5435610657544618)], 'web_search_results': [WebRetrievalResult(source_type='web', source_id='towardsai.net', title='14 Vector Database Optimization Tips for Faster AI Search', url='https://towardsai.net/p/machine-learning/14-vector-database-optimization-tips-for-faster-ai-search', content='* 14 Vector Database Optimization Tips for Faster AI Search. # 14 Vector Database Optimization Tips for Faster AI Search. Vector databases like **Pinecone, Weaviate, Milvus, and FAISS** are the backbone of modern AI applications — from RAG (Retrieval-Augmented Generation) to semantic search and recommendation systems. **Why it matters:** Common queries (e.g., top trending products) can be cached to **avoid repeated expensive vector searches**. By implementing these 14 techniques, engineers can significantly reduce query latency, save memory and operational costs, improve recall and relevance, and deliver reliable, real-time AI search experiences. Whether you are building RAG systems, recommendation engines, or semantic search applications, these optimizations ensure your AI performs at its best. ### Beyond Vector Search: Building an Adaptive Retrieval Router for Agentic AI Systems. ##### Beyond Vector Search: Building an Adaptive Retrieval Router for Agentic AI Systems.', snippet='* 14 Vector Database Optimization Tips for Faster AI Search. # 14 Vector Database Optimization Tips for Faster AI Search. Vector databases like **Pinecone, Weaviate, Milvus, and FAISS** are the backbone of modern AI applications — from RAG (Retrieval-Augmented Generation) to semantic search and recommendation systems. **Why it matters:** Common queries (e.g., top trending products) can be cached to **avoid repeated expensive vector searches**. By implementing these 14 techniques, engineers can s', published_at=None, retrieved_at='2026-01-03T05:35:52.201589', relevance_score=0.6745014), WebRetrievalResult(source_type='web', source_id='dev.to', title='Unlocking the Power of Vector Databases and AI Search', url='https://dev.to/sabaristacksurge/unlocking-the-power-of-vector-databases-and-ai-search-a-comprehensive-guide-12m4', content='Vector Databases: Ideal for similarity searches on high-dimensional data, with applications in recommendation systems, NLP, and computer vision.', snippet='Vector Databases: Ideal for similarity searches on high-dimensional data, with applications in recommendation systems, NLP, and computer vision.', published_at=None, retrieved_at='2026-01-03T05:35:52.202586', relevance_score=0.44927242), WebRetrievalResult(source_type='web', source_id='techwithram.medium.com', title='Vector Databases Unlocked: Your Key Next-Gen AI Search', url='https://techwithram.medium.com/the-ultimate-guide-to-vector-databases-f0bed41a1243', content='A vector database is a purpose-built system designed to store, index, and search through vector embeddings efficiently — especially at scale.', snippet='A vector database is a purpose-built system designed to store, index, and search through vector embeddings efficiently — especially at scale.', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.4179133), WebRetrievalResult(source_type='web', source_id='www.youtube.com', title='Vector Databases: The Secret Weapon for AI Search', url='https://www.youtube.com/watch?v=Ps913CUN1Tw', content=\"Discover how vector databases power fast, intelligent AI search and recommendations. Learn what vector databases are, why they're essential\", snippet=\"Discover how vector databases power fast, intelligent AI search and recommendations. Learn what vector databases are, why they're essential\", published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.3802761), WebRetrievalResult(source_type='web', source_id='www.searchenginejournal.com', title='Introduction To Vector Databases And How To Use AI For ...', url='https://www.searchenginejournal.com/introduction-to-vector-databases-and-how-to-use-ai-for-seo/533993/', content=\"1. Understanding Vector Databases · 2. Create A Vector Database · 3. Export Your Articles From Your CMS · 4. Inserting OpenAi's Text Embeddings\", snippet=\"1. Understanding Vector Databases · 2. Create A Vector Database · 3. Export Your Articles From Your CMS · 4. Inserting OpenAi's Text Embeddings\", published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.36963415), WebRetrievalResult(source_type='web', source_id='vegavid.com', title='How Do Vector Databases Work in AI Applications?', url='https://vegavid.com/blog/how-vector-databases-work-ai', content='Vector databases use specialized indexing techniques that reduce search space and improve performance. These indexes allow the database to', snippet='Vector databases use specialized indexing techniques that reduce search space and improve performance. These indexes allow the database to', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.35763538), WebRetrievalResult(source_type='web', source_id='hackread.com', title='The Power of Vector Databases in the New Era of AI Search', url='https://hackread.com/power-of-vector-databases-era-of-ai-search/', content='Step 1: Translating the World into Numbers with Embeddings · Step 2: The Speed of Search: Introducing the Vector Database · Step 3: Real-World', snippet='Step 1: Translating the World into Numbers with Embeddings · Step 2: The Speed of Search: Introducing the Vector Database · Step 3: Real-World', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.35608885), WebRetrievalResult(source_type='web', source_id='www.oracle.com', title='What Is Vector Search? The Ultimate Guide', url='https://www.oracle.com/database/vector-search/', content='Vector search enables efficient and scalable search in high-dimensional data, allowing for fast retrieval of similar items from large data sets.', snippet='Vector search enables efficient and scalable search in high-dimensional data, allowing for fast retrieval of similar items from large data sets.', published_at=None, retrieved_at='2026-01-03T05:35:52.203589', relevance_score=0.26172626)]}}\n",
      "Evidence checker\n",
      "{'evidence_checker': {'evidence_score': EvidenceScore(coverage=1.0, consistency=1.0, freshness=0.61, source_diversity=9, usable=True)}}\n",
      "{'evaluator': {'next_action': 'summarize'}}\n",
      "{'reducer': {'retries': {'rag': 0, 'web_search': 0, 'synthesis': 0}, 'retrieval_mode': 'both'}}\n",
      "{'summarizer': {'final_response': AIMessage(content='Artificial Intelligence (AI) search leverages vector databases to power fast, intelligent search and recommendations. A vector database is a purpose-built system designed to efficiently store, index, and search through vector embeddings, especially at scale (techwithram.medium.com, www.youtube.com). They are ideal for similarity searches on high-dimensional data and enable efficient, scalable search for fast retrieval of similar items from large datasets (dev.to, www.oracle.com).\\n\\nVector databases serve as the backbone of modern AI applications such as Retrieval-Augmented Generation (RAG), semantic search, and recommendation systems (towardsai.net). They are also applied in Natural Language Processing (NLP) and computer vision (dev.to). The process involves translating data into numerical embeddings and then utilizing vector databases for speed of search (hackread.com).\\n\\nTo achieve faster AI search and better results, various optimization tips can be implemented with vector databases. These optimizations aim to reduce query latency, save memory and operational costs, improve recall and relevance, and deliver reliable, real-time AI search experiences (towardsai.net). For example, common queries can be cached to avoid repeated expensive vector searches. Additionally, vector databases employ specialized indexing techniques to reduce search space and enhance performance (vegavid.com).', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b825a-e2d1-7161-a9d9-07e774ee80b6-0', usage_metadata={'input_tokens': 1126, 'output_tokens': 1710, 'total_tokens': 2836, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1448}})}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function app.llm.qdrant.close_qdrant_client()>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import atexit\n",
    "from app.llm.qdrant import close_qdrant_client\n",
    "\n",
    "initial_state = {\n",
    "    \"user_query\": \"Just tell me something about Artificial Intelligence search for vector db and web search for better results\",\n",
    "    \"rag_results\": [],\n",
    "    \"web_search_results\": [],\n",
    "    \"evidence_score\": None,\n",
    "    \"retries\": {\n",
    "        \"rag\": 0,\n",
    "        \"web_search\": 0,\n",
    "        \"synthesis\": 0\n",
    "    },\n",
    "    \"max_retries\": {\n",
    "        \"rag\": 2,\n",
    "        \"web_search\": 2,\n",
    "        \"synthesis\": 2\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for event in app.stream(\n",
    "    initial_state,\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    print(event)\n",
    "\n",
    "atexit.register(close_qdrant_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beea377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANSWER MODE:\", result[\"answer_mode\"])\n",
    "print(\"RETRIEVAL MODE:\", result[\"retrieval_mode\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['web_search_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f21710",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['rag_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.tools.web_search import web_search\n",
    "web_search(\"recent upgrades in transformer architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
