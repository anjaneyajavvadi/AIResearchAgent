{
  "arxiv_id": "1807.04439v1",
  "title": "Will it Blend? Composing Value Functions in Reinforcement Learning",
  "authors": [
    "Benjamin van Niekerk",
    "Steven James",
    "Adam Earle",
    "Benjamin Rosman"
  ],
  "summary": "An important property for lifelong-learning agents is the ability to combine existing skills to solve unseen tasks. In general, however, it is unclear how to compose skills in a principled way. We provide a \"recipe\" for optimal value function composition in entropy-regularised reinforcement learning (RL) and then extend this to the standard RL setting. Composition is demonstrated in a video game environment, where an agent with an existing library of policies is able to solve new tasks without the need for further learning.",
  "published": "2018-07-12T06:43:12+00:00",
  "updated": "2018-07-12T06:43:12+00:00",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "topic": "reinforcement_learning",
  "pdf_path": "data\\pdfs\\1807.04439v1.pdf",
  "arxiv_url": "http://arxiv.org/abs/1807.04439v1"
}