{
  "arxiv_id": "2311.03226v1",
  "title": "LDM3D-VR: Latent Diffusion Model for 3D VR",
  "authors": [
    "Gabriela Ben Melech Stan",
    "Diana Wofk",
    "Estelle Aflalo",
    "Shao-Yen Tseng",
    "Zhipeng Cai",
    "Michael Paulitsch",
    "Vasudev Lal"
  ],
  "summary": "Latent diffusion models have proven to be state-of-the-art in the creation and manipulation of visual outputs. However, as far as we know, the generation of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite of diffusion models targeting virtual reality development that includes LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD based on textual prompts and the upscaling of low-resolution inputs to high-resolution RGBD, respectively. Our models are fine-tuned from existing pretrained models on datasets containing panoramic/high-resolution RGB images, depth maps and captions. Both models are evaluated in comparison to existing related methods.",
  "published": "2023-11-06T16:12:10+00:00",
  "updated": "2023-11-06T16:12:10+00:00",
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "topic": "diffusion",
  "pdf_path": "data\\pdfs\\2311.03226v1.pdf",
  "arxiv_url": "http://arxiv.org/abs/2311.03226v1"
}